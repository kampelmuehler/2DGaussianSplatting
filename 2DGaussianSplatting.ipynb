{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMX7PqJeE0dyqXR7DqqXrg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kampelmuehler/2DGaussianSplatting/blob/main/2DGaussianSplatting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook provides a vanilla implementation of Gaussian splatting in 2D, which allows to reconstruct an image using a fixed number of 2D Gaussian functions.\n",
        "\n",
        "The implementation is basically following [3DGS](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/), but omits any sort of optimization. Thus, training is comparatively slow and resolution as well as number of Gaussian functions is limited by system/accelerator memory."
      ],
      "metadata": {
        "id": "rdJjySNwwNLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell, enter a url to an image you want to approximate as `target_image_url`.\n",
        "\n"
      ],
      "metadata": {
        "id": "GkYmwqIlv6Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_image_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Carl_Friedrich_Gauss_1840_by_Jensen.jpg/800px-Carl_Friedrich_Gauss_1840_by_Jensen.jpg'\n",
        "target_image_path = 'target'\n",
        "!wget {target_image_url} -O {target_image_path}"
      ],
      "metadata": {
        "id": "AlkQNLYeMtnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell holds the main logic implementing basic Gaussian splatting in 2D following the equations from [3DGS](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/)"
      ],
      "metadata": {
        "id": "z8XpyMFVvbUb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VBv_K_wzBcYk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GaussianSplatting2d(torch.nn.Module):\n",
        "    def __init__(self, n_gaussians, width, height, device, image=None):\n",
        "        \"\"\" initialize GaussianSplatting2d\n",
        "            Args:\n",
        "                n_gaussians: the number of Gaussians to use to approximate an image.\n",
        "                width: width of the image to approximate\n",
        "                height: height of the image to approximate\n",
        "                device: torch.device to run on\n",
        "                image: torch.tensor of target image in range [0, 1].\n",
        "                       if given, initialize colors of Gaussians to closest pixel value in target image.\n",
        "            Returns:\n",
        "                None\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        xs = torch.linspace(0, 1, steps=width)\n",
        "        ys = torch.linspace(0, 1, steps=height)\n",
        "        x, y = torch.meshgrid(xs, ys, indexing='xy')\n",
        "        self.X = torch.cat([x.unsqueeze(-1), y.unsqueeze(-1)], -1).view(-1, 1, 2, 1).to(device)\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.device = device\n",
        "\n",
        "        # parameters of Gaussians\n",
        "        self.scales = torch.nn.Parameter(torch.logit(torch.rand((n_gaussians, 2)) * 0.1), requires_grad=True)\n",
        "        self.rotation_angles = torch.nn.Parameter(torch.logit(torch.rand((n_gaussians, 1))), requires_grad=True)\n",
        "        positions = torch.rand((n_gaussians, 2, 1))\n",
        "        self.positions = torch.nn.Parameter(torch.logit(positions), requires_grad=True)\n",
        "        self.rgbas = torch.rand((n_gaussians, 4))\n",
        "        self.rgbas[:, 3] = (self.rgbas[:, 3] + 0.1) / 1.1  # avoid fully transparent initial alphas\n",
        "        if image is not None:\n",
        "            positions = torch.round(positions.squeeze() * torch.tensor([[image.shape[1] - 1, image.shape[0] - 1]])).int()\n",
        "            self.rgbas[:, :3] = image[positions[:, 1], positions[:, 0], :]\n",
        "        self.rgbas = torch.nn.Parameter(torch.logit(self.rgbas), requires_grad=True)\n",
        "\n",
        "    def covariance_matrices(self):\n",
        "        \"\"\" Calculate covariance matrices given rotation angles and scale\n",
        "            parameters. cf. Eq. 6 in 3DGS paper\n",
        "            Returns:\n",
        "                tensor containing per Gaussian covariance matrices\n",
        "        \"\"\"\n",
        "        scale_matrices = torch.diag_embed(F.sigmoid(self.scales))\n",
        "        cosines = torch.cos(F.sigmoid(self.rotation_angles) * torch.pi)\n",
        "        sines = torch.sin(F.sigmoid(self.rotation_angles) * torch.pi)\n",
        "        rot_matrices = torch.cat([cosines, -sines, sines, cosines], 1).reshape(-1, 2, 2)\n",
        "        return rot_matrices @ scale_matrices @ torch.transpose(scale_matrices, -2, -1) @ torch.transpose(rot_matrices, -2, -1)\n",
        "\n",
        "    def render(self):\n",
        "        \"\"\" Densely evaluate all the Gaussians to generate image\n",
        "            Returns:\n",
        "                image tensor generated from the Gaussian parameters\n",
        "        \"\"\"\n",
        "        # calculate the gaussian weights\n",
        "        x = (self.X - F.sigmoid(self.positions))\n",
        "        gaussians = torch.exp(-0.5 * torch.transpose(x, -2, -1) @ torch.linalg.solve(self.covariance_matrices(), x))\n",
        "        # \"normalize\" individual Gaussians to max 1\n",
        "        norm_gaussians = gaussians / gaussians.max()\n",
        "        # calculate alpha_i (cf. Eq. 3 in 3DGS paper)\n",
        "        alpha_is = norm_gaussians.squeeze() * F.sigmoid(self.rgbas[:, 3])\n",
        "        # blending (cf. Eq. 3 in 3DGS paper)\n",
        "        product = torch.cumprod(torch.cat([torch.ones((alpha_is.shape[0], 1), device=self.device), (1 - alpha_is)[..., :-1]], -1), 1).unsqueeze(-1).to(self.device)\n",
        "        rgb = F.sigmoid(self.rgbas[:, :3]) * alpha_is.unsqueeze(-1) * product\n",
        "        rgb = rgb.sum(1)\n",
        "        return rgb.view(self.height, self.width, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell holds the optimization loop and visualization functionality."
      ],
      "metadata": {
        "id": "SRZ1p6G4vRHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from IPython.display import clear_output\n",
        "\n",
        "NUMBER_OF_OPTIMIZATION_STEPS = 1000\n",
        "NUMBER_OF_GAUSSIANS = 2000\n",
        "MAX_IMAGE_RESOLUTION = 256\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# load image and resize to max MAX_IMAGE_RESOLUTION\n",
        "image = cv2.imread(target_image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "resize_factor = min(MAX_IMAGE_RESOLUTION / max(image.shape[:2]), 1)\n",
        "if resize_factor < 1.:\n",
        "    image = cv2.resize(image, (int(image.shape[1] * resize_factor), int(image.shape[0] * resize_factor)), interpolation=cv2.INTER_AREA)\n",
        "image = torch.tensor(image).float().to(device)\n",
        "image = image / 255\n",
        "\n",
        "# init gaussians and optimizer\n",
        "gs = GaussianSplatting2d(NUMBER_OF_GAUSSIANS, image.shape[1], image.shape[0], device, image).to(device)\n",
        "optimizer = torch.optim.Adam(gs.parameters(), lr=.01)\n",
        "\n",
        "generated_images = []\n",
        "for i in range(NUMBER_OF_OPTIMIZATION_STEPS):\n",
        "    optimizer.zero_grad()\n",
        "    rgb = gs.render()\n",
        "    loss = F.l1_loss(rgb, image)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # visualize\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    axs[0].imshow(image.cpu().numpy())\n",
        "    generated_images.append(torch.clip(rgb, 0, 1).cpu().detach().numpy())\n",
        "    axs[1].imshow(generated_images[-1])\n",
        "    axs[0].set_title(f'Target ({rgb.shape[0] * rgb.shape[1] / 1000:.01f}k px)')\n",
        "    axs[1].set_title(f'Step: {i}, loss: {loss.item():.04f} ({NUMBER_OF_GAUSSIANS / 1000:.01f}k Gaussians)')\n",
        "    axs[0].set_axis_off()\n",
        "    axs[1].set_axis_off()\n",
        "    plt.show()\n",
        "    clear_output(wait=True)\n"
      ],
      "metadata": {
        "id": "TtSLnP5RHD4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the following code to render the individual images of the optimization stage to create a video of the optimization process, such as [this](https://www.youtube.com/watch?v=DLKLgWZ-BGk). Note that this has not been tested within colab.\n",
        "\n",
        "You can subsequently use `ffmpeg` to create a video from the exported images. For example:\n",
        "\n",
        "```ffmpeg -framerate 100 -i %04d.jpg -c:v libx264 -vf \"pad=ceil(iw/2)*2:ceil(ih/2)*2 2dgaussiansplatting.mp4```\n",
        "\n",
        "(run inside the directory containing the exported images)."
      ],
      "metadata": {
        "id": "vlb1NCF6FBbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "out_dir = Path('out')\n",
        "out_dir.mkdir(exist_ok=True)\n",
        "image = cv2.imread(target_image_path)\n",
        "resize_factor = min(MAX_IMAGE_RESOLUTION / max(image.shape[:2]), 1)\n",
        "if resize_factor < 1.:\n",
        "    image = cv2.resize(image, (int(image.shape[1] * resize_factor), int(image.shape[0] * resize_factor)), interpolation=cv2.INTER_AREA)\n",
        "for i, img in enumerate(generated_images):\n",
        "    current_image = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
        "    cv2.imwrite(str(out_dir / f'{i:04d}.jpg'), cv2.hconcat([image, current_image]))"
      ],
      "metadata": {
        "id": "BQpbTUznrH6z"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}